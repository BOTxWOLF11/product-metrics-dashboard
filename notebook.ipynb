{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60cf55be",
   "metadata": {},
   "source": [
    "# Product Metrics Dashboard\n",
    "\n",
    "This notebook loads the synthetic dataset and performs EDA, computes KPIs, and creates plots. See README.md for file list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DF = pd.read_csv('product_metrics_events.csv', parse_dates=['date','reg_date'])\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50286dc7",
   "metadata": {},
   "source": [
    "## Daily metrics (DAU, sessions, revenue, ARPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70644a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = DF.groupby(DF['date'].dt.date).agg(dau=('user_id','nunique'), sessions=('sessions','sum'), revenue=('revenue','sum')).reset_index()\n",
    "daily['date'] = pd.to_datetime(daily['date'])\n",
    "daily['arpu'] = daily['revenue'] / daily['dau'].replace({0:pd.NA})\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf52b7",
   "metadata": {},
   "source": [
    "## Cohort retention (weekly cohorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ac027",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['reg_week'] = DF['reg_date'].dt.to_period('W').apply(lambda r: r.start_time.date())\n",
    "DF['week'] = DF['date'].dt.to_period('W').apply(lambda r: r.start_time.date())\n",
    "cohort = DF.groupby(['reg_week','week']).agg(active_users=('user_id','nunique')).reset_index()\n",
    "cohort['cohort_week'] = ((pd.to_datetime(cohort['week']) - pd.to_datetime(cohort['reg_week'])).dt.days // 7).astype(int)\n",
    "cohort_pivot = cohort.pivot_table(values='active_users', index='reg_week', columns='cohort_week', aggfunc='sum').fillna(0)\n",
    "cohort_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c922c",
   "metadata": {},
   "source": [
    "## Plots (saved to files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DAU\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(daily['date'], daily['dau'])\n",
    "plt.title('Daily Active Users (DAU)')\n",
    "plt.show()\n",
    "\n",
    "# ARPU\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(daily['date'], daily['arpu'])\n",
    "plt.title('Daily ARPU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adb24c9",
   "metadata": {},
   "source": [
    "## SQL queries\n",
    "See `product_metrics_queries.sql` for ready-to-use SQL examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d5e0f",
   "metadata": {},
   "source": [
    "## LTV by cohort\n",
    "The following cells compute average cumulative revenue (LTV) per cohort-week and plot cohort LTV trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06cd95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LTV by cohort\n",
    "DF = pd.read_csv('product_metrics_events.csv', parse_dates=['date','reg_date'])\n",
    "DF['reg_week'] = DF['reg_date'].dt.to_period('W').apply(lambda r: r.start_time.date())\n",
    "DF['week'] = DF['date'].dt.to_period('W').apply(lambda r: r.start_time.date())\n",
    "DF['cohort_week'] = ((pd.to_datetime(DF['week']) - pd.to_datetime(DF['reg_week'])).dt.days // 7).astype(int)\n",
    "\n",
    "user_week = DF.groupby(['reg_week','cohort_week','user_id']).agg(user_revenue=('revenue','sum')).reset_index()\n",
    "user_week = user_week.sort_values(['reg_week','user_id','cohort_week'])\n",
    "user_week['cum_revenue'] = user_week.groupby(['reg_week','user_id'])['user_revenue'].cumsum()\n",
    "\n",
    "ltv = user_week.groupby(['reg_week','cohort_week']).agg(users_in_cohort=('user_id','nunique'), avg_cum_revenue=('cum_revenue','mean')).reset_index()\n",
    "ltv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae587dfc",
   "metadata": {},
   "source": [
    "## RFM segmentation\n",
    "Calculate Recency (days since last activity), Frequency (number of active days), Monetary (total revenue) per user. Then create R/F/M quintiles and basic segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFM calculation\n",
    "DF = pd.read_csv('product_metrics_events.csv', parse_dates=['date','reg_date'])\n",
    "reference_date = DF['date'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "user_agg = DF.groupby('user_id').agg(last_date=('date','max'), active_days=('date','nunique'), total_revenue=('revenue','sum')).reset_index()\n",
    "user_agg['recency_days'] = (reference_date - pd.to_datetime(user_agg['last_date'])).dt.days\n",
    "user_agg['frequency'] = user_agg['active_days']\n",
    "user_agg['monetary'] = user_agg['total_revenue']\n",
    "\n",
    "user_agg['r_quintile'] = pd.qcut(user_agg['recency_days'].rank(method='first'), 5, labels=[5,4,3,2,1]).astype(int)\n",
    "user_agg['f_quintile'] = pd.qcut(user_agg['frequency'].rank(method='first'), 5, labels=[1,2,3,4,5]).astype(int)\n",
    "user_agg['m_quintile'] = pd.qcut(user_agg['monetary'].rank(method='first'), 5, labels=[1,2,3,4,5]).astype(int)\n",
    "\n",
    "user_agg['RFM_score'] = user_agg['r_quintile'].astype(str) + user_agg['f_quintile'].astype(str) + user_agg['m_quintile'].astype(str)\n",
    "user_agg['RFM_numeric'] = user_agg['r_quintile']*100 + user_agg['f_quintile']*10 + user_agg['m_quintile']\n",
    "\n",
    "def rfm_segment(x):\n",
    "    if x >= 100 and x < 233:\n",
    "        return 'Champions'\n",
    "    if x >= 233 and x < 344:\n",
    "        return 'Loyal'\n",
    "    if x >= 344 and x < 455:\n",
    "        return 'Potential'\n",
    "    if x >= 455 and x < 566:\n",
    "        return 'At Risk'\n",
    "    return 'Hibernating'\n",
    "\n",
    "user_agg['segment'] = user_agg['RFM_numeric'].apply(rfm_segment)\n",
    "user_agg.head()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
